{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashok/kc/kagglenv/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import hyperopt as ht\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "def _initialize_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "random_state = 42\n",
    "_initialize_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../input/ravdess/\"\n",
    "df_train = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "df_valid = pd.read_csv(os.path.join(data_dir, \"valid.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signals(df, sr=44100, **kwargs):\n",
    "    singals = []\n",
    "    for row in tqdm(df.itertuples(), desc=\"Processing...\", total=len(df)):\n",
    "        audio_signal,_ = librosa.core.load(os.path.join(data_dir, row.filepath), sr=sr, offset=kwargs.get(\"offset\", 0.25), duration=kwargs.get(\"duration\", 2.5))\n",
    "        singals.append(audio_signal)\n",
    "    return np.array(singals, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_features(signal, postfeatures=\"standardize\", return_dims=1):\n",
    "    assert(postfeatures in [\"standardize\",\"normalize\"])\n",
    "    assert(return_dims in [1,2])\n",
    "\n",
    "    # Get MFCC\n",
    "    x = librosa.feature.mfcc(y=signal)\n",
    "\n",
    "    # Postprocess\n",
    "    if postfeatures==\"standardize\":\n",
    "        x = StandardScaler().fit_transform(x.T).T\n",
    "    elif postfeatures==\"normalize\":\n",
    "        x = 2.*(x - x.min(axis=1).reshape(-1,1))/(x.max(axis=1)-x.min(axis=1)).reshape(-1,1) - 1\n",
    "    \n",
    "    # Return\n",
    "    return x.ravel() if return_dims==1 else x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 990/990 [01:04<00:00, 15.40it/s]\n",
      "Processing...: 100%|██████████| 330/330 [00:18<00:00, 18.28it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = load_signals(df_train)\n",
    "X_valid = load_signals(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mfcc1D = np.array([get_mfcc_features(x, postfeatures=\"standardize\", return_dims=1) for x in X_train])\n",
    "X_valid_mfcc1D = np.array([get_mfcc_features(x, postfeatures=\"standardize\", return_dims=1) for x in X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"emotion\"].values\n",
    "y_valid = df_valid[\"emotion\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 4320) (990,)\n",
      "(330, 4320) (330,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_mfcc1D.shape, y_train.shape)\n",
    "print(X_valid_mfcc1D.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:28<00:00,  1.77s/trial, best loss: -0.3484848484848485]\n",
      "{'colsample_bytree': 0.697604236265011, 'gamma': 2.1625624460965795, 'max_depth': 7.0, 'min_child_weight': 9.0, 'reg_lambda': 7.181656340878593}\n"
     ]
    }
   ],
   "source": [
    "# Define space\n",
    "space = {'max_depth': ht.hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "    'gamma': ht.hp.uniform ('gamma', 1, 9),\n",
    "    'reg_lambda' : ht.hp.uniform('reg_lambda', 0, 10),\n",
    "    'colsample_bytree' : ht.hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight' : ht.hp.quniform('min_child_weight', 0, 10, 1),\n",
    "    'n_estimators': 180,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Objective function\n",
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "        n_estimators=space['n_estimators'],\n",
    "        max_depth=int(space['max_depth']),\n",
    "        gamma=space['gamma'],\n",
    "        min_child_weight=int(space['min_child_weight']),\n",
    "        colsample_bytree=int(space['colsample_bytree']),\n",
    "        eval_metric=\"auc\",\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_mfcc1D, y_train, eval_set=[(X_valid_mfcc1D, y_valid)], verbose=False)\n",
    "    accuracy = accuracy_score(y_valid, clf.predict(X_valid_mfcc1D))\n",
    "    \n",
    "    return {'loss': -accuracy, 'status': ht.STATUS_OK}\n",
    "\n",
    "# Run trials\n",
    "trials = ht.Trials()\n",
    "best_hyperparams = ht.fmin(\n",
    "    fn = objective,\n",
    "    space = space,\n",
    "    algo = ht.tpe.suggest,\n",
    "    max_evals = 50,\n",
    "    trials = trials\n",
    ")\n",
    "\n",
    "# Obtain best hyperparams\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [180,3,2.81,3.87,3.5,0.95]\n",
    "# Find and fill best hyperparams for this model\n",
    "xgbc = xgb.XGBClassifier(\n",
    "    n_estimators=180,\n",
    "    max_depth=6,\n",
    "    gamma=2.5,\n",
    "    reg_lambda=6,\n",
    "    min_child_weight=10,\n",
    "    colsample_bytree=0.75,\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"gpu_hist\"\n",
    ")\n",
    "\n",
    "xgbc.fit(X_train_mfcc1D, y_train)\n",
    "y_hat_train = xgbc.predict(X_train_mfcc1D)\n",
    "y_hat_valid = xgbc.predict(X_valid_mfcc1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 0.9959595959595959\n",
      "Accuracy (valid): 0.37272727272727274\n",
      "F1 (train): 0.9962046181687604\n",
      "F1 (valid): 0.36303169094477716\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (train):\",accuracy_score(y_train, y_hat_train))\n",
    "print(\"Accuracy (valid):\",accuracy_score(y_valid, y_hat_valid))\n",
    "print(\"F1 (train):\",f1_score(y_train, y_hat_train, average=\"macro\"))\n",
    "print(\"F1 (valid):\",f1_score(y_valid, y_hat_valid, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(facecolor=\"white\")\n",
    "sns.heatmap(confusion_matrix(y_valid, y_hat_valid), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.predict([X_valid_mfcc1D[0]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/xgbc_v1_stdmfcc1D_2.5ms.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgbc, \"../models/xgbc_v1_stdmfcc1D_2.5ms.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/huseinzol05/sound-augmentation-librosa/notebook\n",
    "def pitch_shift(signal, sr=44100):\n",
    "    bins_per_octave = 12\n",
    "    pitch_pm = 2\n",
    "    pitch_change =  pitch_pm * 2*(np.random.uniform())\n",
    "    return librosa.effects.pitch_shift(signal.astype('float32'), sr=sr, n_steps=pitch_change, bins_per_octave=bins_per_octave)\n",
    "\n",
    "def value_augmentation(signal, low=1.5, high=3):\n",
    "    dyn_change = np.random.uniform(low=low,high=high)\n",
    "    return signal * dyn_change\n",
    "\n",
    "def hpss(signal):\n",
    "    return librosa.effects.hpss(signal.astype('float64'))[1]\n",
    "\n",
    "def distribution_noise(signal):\n",
    "    noise_amp = 0.005*np.random.uniform()*np.amax(signal)\n",
    "    return signal.astype('float64') + noise_amp * np.random.normal(size=signal.shape[0])\n",
    "\n",
    "\n",
    "class RavdessDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, paug=0.5) -> None:\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "        self.paug = paug\n",
    "        self.transforms = {\n",
    "            \"pitch_shift\":pitch_shift,\n",
    "            \"value_augmentation\":value_augmentation,\n",
    "            \"hpss\":hpss,\n",
    "            \"distribution_noise\":distribution_noise\n",
    "        }   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.X[i], self.y[i]\n",
    "        if np.random.random()<self.paug:\n",
    "            transform_name = np.random.choice(list(self.transforms.keys()))\n",
    "            x = self.transforms[transform_name](x)\n",
    "        x = get_mfcc_features(x, postfeatures=\"standardize\", return_dims=2)\n",
    "        x = x.astype(np.float32).T\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "train_dataset = RavdessDataset(X_train, y_train, paug=0.4)\n",
    "valid_dataset = RavdessDataset(X_valid, y_valid, paug=0.0)\n",
    "\n",
    "# Initialize dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_classes = 16\n",
    "\n",
    "class GetLSTMFeatures(torch.nn.Module):\n",
    "    def __init__(self, mode, batch_first=True) -> None:\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.batch_first = batch_first\n",
    "    def forward(self, x):\n",
    "        output, (hn, cn) = x\n",
    "        if self.mode==\"full\":\n",
    "            return output\n",
    "        return output[:,-1,:] if self.batch_first else output[-1,:,:]\n",
    "\n",
    "lstm_model = torch.nn.Sequential(\n",
    "    torch.nn.LSTM(input_size=20, hidden_size=64, num_layers=3, dropout=0.2, batch_first=True),\n",
    "    # GetLSTMFeatures(mode=\"full\"),\n",
    "    # torch.nn.LSTM(input_size=16, hidden_size=8, num_layers=2),\n",
    "    GetLSTMFeatures(mode=\"last\"),\n",
    "    torch.nn.Linear(in_features=64, out_features=32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=32, out_features=n_classes)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training loss: 2.735774517059326, Training accuracy: 0.09967096002252251, Validation loss: 2.713118076324463, Validation accuracy: 0.08350929054054054\n",
      "Epoch: 10, Training loss: 2.4937174916267395, Training accuracy: 0.13789766328828829, Validation loss: 2.457340717315674, Validation accuracy: 0.1570945945945946\n",
      "Epoch: 15, Training loss: 2.249662756919861, Training accuracy: 0.20272029842342343, Validation loss: 2.2025636434555054, Validation accuracy: 0.1746727195945946\n",
      "Epoch: 20, Training loss: 2.077507972717285, Training accuracy: 0.24913780968468469, Validation loss: 2.0362237095832825, Validation accuracy: 0.21853885135135137\n",
      "Epoch: 25, Training loss: 1.9909188449382782, Training accuracy: 0.27054300394144143, Validation loss: 1.9760764241218567, Validation accuracy: 0.24165962837837837\n",
      "Epoch: 30, Training loss: 1.9442033171653748, Training accuracy: 0.30418602195945943, Validation loss: 1.9072966575622559, Validation accuracy: 0.2505278716216216\n",
      "Epoch: 35, Training loss: 1.8160374164581299, Training accuracy: 0.3147786458333333, Validation loss: 1.8840190768241882, Validation accuracy: 0.2951330236486487\n",
      "Epoch: 40, Training loss: 1.7732615768909454, Training accuracy: 0.35639252533783783, Validation loss: 1.8275296092033386, Validation accuracy: 0.3079075168918919\n",
      "Epoch: 45, Training loss: 1.6766657531261444, Training accuracy: 0.37231665259009006, Validation loss: 1.8608970642089844, Validation accuracy: 0.25744298986486486\n",
      "Epoch: 50, Training loss: 1.592370092868805, Training accuracy: 0.428271044481982, Validation loss: 1.7815297842025757, Validation accuracy: 0.34559755067567566\n",
      "Epoch: 55, Training loss: 1.5451762080192566, Training accuracy: 0.44884923986486486, Validation loss: 1.7872156500816345, Validation accuracy: 0.32801942567567566\n",
      "Epoch: 60, Training loss: 1.4637972116470337, Training accuracy: 0.45748873873873874, Validation loss: 1.7671947479248047, Validation accuracy: 0.3388407939189189\n",
      "Epoch: 65, Training loss: 1.4805662035942078, Training accuracy: 0.48639850788288286, Validation loss: 1.7771119475364685, Validation accuracy: 0.38328758445945943\n",
      "Epoch: 70, Training loss: 1.4049833416938782, Training accuracy: 0.5004486908783784, Validation loss: 1.767841637134552, Validation accuracy: 0.3610641891891892\n",
      "Epoch: 75, Training loss: 1.2904400825500488, Training accuracy: 0.5544499577702703, Validation loss: 1.7649664878845215, Validation accuracy: 0.33599028716216217\n",
      "Epoch: 80, Training loss: 1.2161697447299957, Training accuracy: 0.5716497747747747, Validation loss: 1.7602347135543823, Validation accuracy: 0.35161528716216217\n",
      "Epoch: 85, Training loss: 1.273799329996109, Training accuracy: 0.5601597691441441, Validation loss: 1.8015725016593933, Validation accuracy: 0.36993243243243246\n",
      "Epoch: 90, Training loss: 1.183259516954422, Training accuracy: 0.5899757179054054, Validation loss: 1.8567967414855957, Validation accuracy: 0.36211993243243246\n",
      "Epoch: 95, Training loss: 1.075990080833435, Training accuracy: 0.6240762246621622, Validation loss: 1.728837490081787, Validation accuracy: 0.38930532094594594\n",
      "Epoch: 100, Training loss: 1.049704223871231, Training accuracy: 0.6162637246621622, Validation loss: 1.7954691052436829, Validation accuracy: 0.36903505067567566\n",
      "Epoch: 105, Training loss: 0.9794944226741791, Training accuracy: 0.6638073620495495, Validation loss: 1.7997800707817078, Validation accuracy: 0.3604835304054054\n",
      "Epoch: 110, Training loss: 0.9838617593050003, Training accuracy: 0.6550182995495495, Validation loss: 1.794779658317566, Validation accuracy: 0.3942673141891892\n",
      "Epoch: 115, Training loss: 0.9921780228614807, Training accuracy: 0.6723676801801801, Validation loss: 1.8076000213623047, Validation accuracy: 0.3779032939189189\n",
      "Epoch: 120, Training loss: 0.928583413362503, Training accuracy: 0.6855908643018018, Validation loss: 1.8433759212493896, Validation accuracy: 0.3857157939189189\n",
      "Epoch: 125, Training loss: 0.9128217548131943, Training accuracy: 0.7039959881756757, Validation loss: 1.8285387754440308, Validation accuracy: 0.38661317567567566\n",
      "Epoch: 130, Training loss: 0.8442634791135788, Training accuracy: 0.7341902449324325, Validation loss: 1.9183627367019653, Validation accuracy: 0.38466005067567566\n",
      "Epoch: 135, Training loss: 0.9577946811914444, Training accuracy: 0.6794411599099099, Validation loss: 1.8714648485183716, Validation accuracy: 0.40102407094594594\n",
      "Epoch: 140, Training loss: 0.8277930915355682, Training accuracy: 0.7199113175675675, Validation loss: 1.8130984902381897, Validation accuracy: 0.42609797297297297\n",
      "Epoch: 145, Training loss: 0.7993105947971344, Training accuracy: 0.7630296311936937, Validation loss: 1.8151285648345947, Validation accuracy: 0.41348184121621623\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_465774/980102777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_465774/620138622.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtransform_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransform_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mfcc_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"standardize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_465774/620138622.py\u001b[0m in \u001b[0;36mhpss\u001b[0;34m(signal)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhpss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhpss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdistribution_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/librosa/effects.py\u001b[0m in \u001b[0;36mhpss\u001b[0;34m(y, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Decompose into harmonic and percussives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mstft_harm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhpss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Invert the STFTs.  Adjust length to match the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/librosa/decompose.py\u001b[0m in \u001b[0;36mhpss\u001b[0;34m(S, kernel_size, power, mask, margin)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;31m# Compute median filters. Pre-allocation here preserves memory layout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mharm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mharm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mharm_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reflect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mperc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mmedian_filter\u001b[0;34m(input, size, footprint, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m   1393\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \"\"\"\n\u001b[0;32m-> 1395\u001b[0;31m     return _rank_filter(input, 0, size, footprint, output, mode, cval,\n\u001b[0m\u001b[1;32m   1396\u001b[0m                         origin, 'median')\n\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kc/kagglenv/lib/python3.8/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36m_rank_filter\u001b[0;34m(input, rank, size, footprint, output, mode, cval, origin, operation)\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \"filters\")\n\u001b[1;32m   1301\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         _nd_image.rank_filter(input, rank, footprint, output, mode, cval,\n\u001b[0m\u001b[1;32m   1303\u001b[0m                               origins)\n\u001b[1;32m   1304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtemp_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001, amsgrad=True)\n",
    "epochs = 1000\n",
    "verbose_step = 5\n",
    "min_validation_loss = np.float32('inf')\n",
    "\n",
    "# Epoch runner\n",
    "for epoch in range(epochs):\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    validation_loss = []\n",
    "    validation_accuracy = []\n",
    "\n",
    "    # Training\n",
    "    for inputs, targets in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_model(inputs.to(device))\n",
    "        loss = criterion(outputs, targets.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss.append(loss.mean().item())\n",
    "        training_accuracy.append((torch.nn.functional.softmax(outputs, dim=1).cpu().detach().numpy().argmax(axis=1)==targets.cpu().detach().numpy()).sum()/len(targets))\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_dataloader:\n",
    "            outputs = lstm_model(inputs.to(device))\n",
    "            loss = criterion(outputs, targets.to(device))\n",
    "            validation_loss.append(loss.mean().item())\n",
    "            validation_accuracy.append((torch.nn.functional.softmax(outputs, dim=1).cpu().detach().numpy().argmax(axis=1)==targets.cpu().detach().numpy()).sum()/len(targets))\n",
    "    \n",
    "    # Verbose metrics\n",
    "    if (epoch+1)%verbose_step==0:\n",
    "        print(f\"Epoch: {epoch+1}\", end=\", \")\n",
    "        print(\"Training loss:\", np.mean(training_loss), end=\", \")\n",
    "        print(\"Training accuracy:\", np.mean(training_accuracy), end=\", \")\n",
    "        print(\"Validation loss:\", np.mean(validation_loss), end=\", \")\n",
    "        print(\"Validation accuracy:\", np.mean(validation_accuracy))\n",
    "    \n",
    "    # Save\n",
    "    if np.mean(validation_loss) < min_validation_loss:\n",
    "        min_validation_loss = np.mean(validation_loss)\n",
    "        torch.save(lstm_model.state_dict(), \"../models/lstm_v3_stdmfcc2D_2.5ms.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8167593479156494\n"
     ]
    }
   ],
   "source": [
    "print(min_validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_spectrogram(spectrogram):\n",
    "    fig, ax = plt.subplots(facecolor=\"white\")\n",
    "    img = librosa.display.specshow(spectrogram, x_axis='time',\n",
    "                        y_axis='mel', sr=44100,\n",
    "                        fmax=8000, ax=ax)\n",
    "    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    ax.set(title='Mel-frequency spectrogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RavdessImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, paug=0.5) -> None:\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "        self.paug = paug\n",
    "        self.transforms = {\n",
    "            \"pitch_shift\":pitch_shift,\n",
    "            \"value_augmentation\":value_augmentation,\n",
    "            \"hpss\":hpss,\n",
    "            \"distribution_noise\":distribution_noise\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.X[i], self.y[i]\n",
    "        if np.random.random()<self.paug:\n",
    "            transform_name = np.random.choice(list(self.transforms.keys()))\n",
    "            x = self.transforms[transform_name](x)\n",
    "        x = librosa.feature.melspectrogram(y=x, sr=44100, n_fft=1380, hop_length=345)/255.\n",
    "        return x.astype(np.float32), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "train_imagedataset = RavdessImageDataset(X_train, y_train, paug=0.4)\n",
    "valid_imagedataset = RavdessImageDataset(X_valid, y_valid, paug=0.0)\n",
    "\n",
    "# Initialize dataloader\n",
    "train_imagedataloader = torch.utils.data.DataLoader(train_imagedataset, batch_size=256)\n",
    "valid_imagedataloader = torch.utils.data.DataLoader(valid_imagedataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_classes = 16\n",
    "\n",
    "cnn_model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 32, 3, 2), # [?,1,128,320] -> [?,32,63,159]\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 64, 3, 2), # [?,32,63,159] -> [?,64,31,79]\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2), # [?,64,31,79] -> [?,64,15,39]\n",
    "    torch.nn.Conv2d(64, 128, 3, 2), # [?,64,15,39] -> [?,128,7,19]\n",
    "    torch.nn.BatchNorm2d(128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2), # [?,128,7,19] -> [?,128,3,9]\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(128*3*9, n_classes)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training loss: 2.1340070962905884, Training accuracy: 0.35992046734234234, Validation loss: 2.422752618789673, Validation accuracy: 0.24751900337837837\n",
      "Epoch: 20, Training loss: 1.5403814911842346, Training accuracy: 0.5243260838963963, Validation loss: 2.088812828063965, Validation accuracy: 0.3214210304054054\n",
      "Epoch: 30, Training loss: 0.9721923023462296, Training accuracy: 0.7013566300675675, Validation loss: 1.9825977087020874, Validation accuracy: 0.36000844594594594\n",
      "Epoch: 40, Training loss: 0.6203436627984047, Training accuracy: 0.8186057150900901, Validation loss: 1.8823872804641724, Validation accuracy: 0.41934121621621623\n",
      "Epoch: 50, Training loss: 0.4816228896379471, Training accuracy: 0.8710409628378378, Validation loss: 1.8567222952842712, Validation accuracy: 0.45703125\n",
      "Epoch: 60, Training loss: 0.3541188910603523, Training accuracy: 0.9022029842342343, Validation loss: 2.0359250903129578, Validation accuracy: 0.4259396114864865\n",
      "Epoch: 70, Training loss: 0.34351786971092224, Training accuracy: 0.9124173001126126, Validation loss: 2.0161431431770325, Validation accuracy: 0.4582453547297297\n",
      "Epoch: 80, Training loss: 0.30227720737457275, Training accuracy: 0.9281918637387387, Validation loss: 2.1553642749786377, Validation accuracy: 0.4513302364864865\n",
      "Epoch: 90, Training loss: 0.278773695230484, Training accuracy: 0.9313502956081081, Validation loss: 2.136447310447693, Validation accuracy: 0.4543391047297297\n",
      "Epoch: 100, Training loss: 0.23052847757935524, Training accuracy: 0.9360043637387387, Validation loss: 2.078865706920624, Validation accuracy: 0.486328125\n",
      "Epoch: 110, Training loss: 0.18196208029985428, Training accuracy: 0.9506528012387387, Validation loss: 2.1142131090164185, Validation accuracy: 0.46516047297297297\n",
      "Epoch: 120, Training loss: 0.1769610121846199, Training accuracy: 0.9510311092342343, Validation loss: 2.1341596841812134, Validation accuracy: 0.42520059121621623\n",
      "Epoch: 130, Training loss: 0.1771480031311512, Training accuracy: 0.9508023648648649, Validation loss: 2.0605658888816833, Validation accuracy: 0.4747677364864865\n",
      "Epoch: 140, Training loss: 0.19368040561676025, Training accuracy: 0.9423916103603603, Validation loss: 2.0853689312934875, Validation accuracy: 0.47761824324324326\n",
      "Epoch: 150, Training loss: 0.1420764960348606, Training accuracy: 0.963647240990991, Validation loss: 2.10229229927063, Validation accuracy: 0.44863809121621623\n",
      "Epoch: 160, Training loss: 0.12633551470935345, Training accuracy: 0.9712309966216216, Validation loss: 2.091160237789154, Validation accuracy: 0.45930109797297297\n",
      "Epoch: 170, Training loss: 0.1193251833319664, Training accuracy: 0.9683804898648649, Validation loss: 2.168951630592346, Validation accuracy: 0.4719172297297297\n",
      "Epoch: 180, Training loss: 0.11912132427096367, Training accuracy: 0.967553490990991, Validation loss: 2.226626396179199, Validation accuracy: 0.4825802364864865\n",
      "Epoch: 190, Training loss: 0.12563269212841988, Training accuracy: 0.9643246762387387, Validation loss: 2.3740049600601196, Validation accuracy: 0.46980574324324326\n",
      "Epoch: 200, Training loss: 0.11058059893548489, Training accuracy: 0.9735624296171171, Validation loss: 2.1410163044929504, Validation accuracy: 0.507495777027027\n",
      "Epoch: 210, Training loss: 0.09818672016263008, Training accuracy: 0.9738615568693694, Validation loss: 2.1605984568595886, Validation accuracy: 0.4884396114864865\n",
      "Epoch: 220, Training loss: 0.09788751229643822, Training accuracy: 0.9769408079954955, Validation loss: 2.4467179775238037, Validation accuracy: 0.48347761824324326\n",
      "Epoch: 230, Training loss: 0.11793791502714157, Training accuracy: 0.968530053490991, Validation loss: 2.420964002609253, Validation accuracy: 0.47957136824324326\n",
      "Epoch: 240, Training loss: 0.11608521081507206, Training accuracy: 0.9706327421171171, Validation loss: 2.2022998332977295, Validation accuracy: 0.486328125\n",
      "Epoch: 250, Training loss: 0.08970248512923717, Training accuracy: 0.9788939329954955, Validation loss: 2.370726466178894, Validation accuracy: 0.45270270270270274\n",
      "Epoch: 260, Training loss: 0.06285770423710346, Training accuracy: 0.9839263091216216, Validation loss: 2.159277021884918, Validation accuracy: 0.5037478885135135\n",
      "Epoch: 270, Training loss: 0.10397136583924294, Training accuracy: 0.9730345579954955, Validation loss: 2.2290465235710144, Validation accuracy: 0.5\n",
      "Epoch: 280, Training loss: 0.07580491341650486, Training accuracy: 0.9816740568693694, Validation loss: 2.2281134128570557, Validation accuracy: 0.4689083614864865\n",
      "Epoch: 290, Training loss: 0.048790670931339264, Training accuracy: 0.9897856841216216, Validation loss: 2.307959198951721, Validation accuracy: 0.4845333614864865\n",
      "Epoch: 300, Training loss: 0.06164967641234398, Training accuracy: 0.9873838682432432, Validation loss: 2.3510146141052246, Validation accuracy: 0.4669552364864865\n",
      "Epoch: 310, Training loss: 0.06919244304299355, Training accuracy: 0.9755155546171171, Validation loss: 2.3956218957901, Validation accuracy: 0.4920291385135135\n",
      "Epoch: 320, Training loss: 0.08143377676606178, Training accuracy: 0.9813749296171171, Validation loss: 2.3944027423858643, Validation accuracy: 0.4939822635135135\n",
      "Epoch: 330, Training loss: 0.11226275376975536, Training accuracy: 0.9710110501126126, Validation loss: 2.6658395528793335, Validation accuracy: 0.474609375\n",
      "Epoch: 340, Training loss: 0.07487448770552874, Training accuracy: 0.9777678068693694, Validation loss: 2.524500250816345, Validation accuracy: 0.48543074324324326\n",
      "Epoch: 350, Training loss: 0.09174169227480888, Training accuracy: 0.9737119932432432, Validation loss: 2.6150641441345215, Validation accuracy: 0.4601984797297297\n",
      "Epoch: 360, Training loss: 0.06683703139424324, Training accuracy: 0.981225365990991, Validation loss: 2.4493820667266846, Validation accuracy: 0.48347761824324326\n",
      "Epoch: 370, Training loss: 0.06483194977045059, Training accuracy: 0.9811461852477478, Validation loss: 2.3742780685424805, Validation accuracy: 0.48152449324324326\n",
      "Epoch: 380, Training loss: 0.0478523513302207, Training accuracy: 0.9885099943693694, Validation loss: 2.5014911890029907, Validation accuracy: 0.490234375\n",
      "Epoch: 390, Training loss: 0.05892926640808582, Training accuracy: 0.9842254363738738, Validation loss: 2.599451184272766, Validation accuracy: 0.5078125\n",
      "Epoch: 400, Training loss: 0.053928554989397526, Training accuracy: 0.9878325591216216, Validation loss: 2.5414834022521973, Validation accuracy: 0.490234375\n",
      "Epoch: 410, Training loss: 0.038529643788933754, Training accuracy: 0.9921875, Validation loss: 2.4734023809432983, Validation accuracy: 0.46906672297297297\n",
      "Epoch: 420, Training loss: 0.052147384732961655, Training accuracy: 0.9811461852477478, Validation loss: 2.5276941061019897, Validation accuracy: 0.4689083614864865\n",
      "Epoch: 430, Training loss: 0.04154016217216849, Training accuracy: 0.9891082488738738, Validation loss: 2.516851544380188, Validation accuracy: 0.4929265202702703\n",
      "Epoch: 440, Training loss: 0.03642986575141549, Training accuracy: 0.9897856841216216, Validation loss: 2.3737415075302124, Validation accuracy: 0.47101984797297297\n",
      "Epoch: 450, Training loss: 0.04891068767756224, Training accuracy: 0.9849028716216216, Validation loss: 2.4926416873931885, Validation accuracy: 0.5069151182432432\n",
      "Epoch: 460, Training loss: 0.02754621673375368, Training accuracy: 0.9959441863738738, Validation loss: 2.660759449005127, Validation accuracy: 0.46906672297297297\n",
      "Epoch: 470, Training loss: 0.05771187134087086, Training accuracy: 0.9798704954954955, Validation loss: 2.482542872428894, Validation accuracy: 0.5105046452702703\n",
      "Epoch: 480, Training loss: 0.03511405969038606, Training accuracy: 0.9909118102477478, Validation loss: 2.4101747274398804, Validation accuracy: 0.48933699324324326\n",
      "Epoch: 490, Training loss: 0.03929559513926506, Training accuracy: 0.9886595579954955, Validation loss: 2.4228681325912476, Validation accuracy: 0.505542652027027\n",
      "Epoch: 500, Training loss: 0.038190051447600126, Training accuracy: 0.9907622466216216, Validation loss: 2.562463879585266, Validation accuracy: 0.47941300675675674\n",
      "Epoch: 510, Training loss: 0.03485769871622324, Training accuracy: 0.9920379363738738, Validation loss: 2.3957815170288086, Validation accuracy: 0.5115603885135135\n",
      "Epoch: 520, Training loss: 0.0321194501593709, Training accuracy: 0.9921875, Validation loss: 2.6212364435195923, Validation accuracy: 0.49308488175675674\n",
      "Epoch: 530, Training loss: 0.028834636323153973, Training accuracy: 0.9918883727477478, Validation loss: 2.6154552698135376, Validation accuracy: 0.49699113175675674\n",
      "Epoch: 540, Training loss: 0.02822975441813469, Training accuracy: 0.9948180602477478, Validation loss: 2.6807119846343994, Validation accuracy: 0.5096072635135135\n",
      "Epoch: 550, Training loss: 0.02641880325973034, Training accuracy: 0.994140625, Validation loss: 2.5216084718704224, Validation accuracy: 0.505859375\n",
      "Epoch: 560, Training loss: 0.033193079521879554, Training accuracy: 0.9894865568693694, Validation loss: 2.7283512353897095, Validation accuracy: 0.4728146114864865\n",
      "Epoch: 570, Training loss: 0.03588645625859499, Training accuracy: 0.9876829954954955, Validation loss: 2.547321915626526, Validation accuracy: 0.4982052364864865\n",
      "Epoch: 580, Training loss: 0.02160600759088993, Training accuracy: 0.9939910613738738, Validation loss: 2.733652353286743, Validation accuracy: 0.4998416385135135\n",
      "Epoch: 590, Training loss: 0.022471004631370306, Training accuracy: 0.9938414977477478, Validation loss: 2.5446470975875854, Validation accuracy: 0.5398015202702703\n",
      "Epoch: 600, Training loss: 0.020743674831464887, Training accuracy: 0.9951171875, Validation loss: 2.7723629474639893, Validation accuracy: 0.48933699324324326\n",
      "Epoch: 610, Training loss: 0.040874948259443045, Training accuracy: 0.9879821227477478, Validation loss: 2.560388684272766, Validation accuracy: 0.5222233952702703\n",
      "Epoch: 620, Training loss: 0.018292896216735244, Training accuracy: 0.9970703125, Validation loss: 2.7634249925613403, Validation accuracy: 0.4689083614864865\n",
      "Epoch: 630, Training loss: 0.025208760052919388, Training accuracy: 0.9938414977477478, Validation loss: 2.8324995040893555, Validation accuracy: 0.4650021114864865\n",
      "Epoch: 640, Training loss: 0.022448761854320765, Training accuracy: 0.9949676238738738, Validation loss: 2.7384209632873535, Validation accuracy: 0.49894425675675674\n",
      "Epoch: 650, Training loss: 0.024932824540883303, Training accuracy: 0.9909118102477478, Validation loss: 2.8759433031082153, Validation accuracy: 0.4797297297297297\n",
      "Epoch: 660, Training loss: 0.025588573422282934, Training accuracy: 0.9928649352477478, Validation loss: 3.0899561643600464, Validation accuracy: 0.43422719594594594\n",
      "Epoch: 670, Training loss: 0.0240919099887833, Training accuracy: 0.99609375, Validation loss: 2.790701150894165, Validation accuracy: 0.4747677364864865\n",
      "Epoch: 680, Training loss: 0.02582474029622972, Training accuracy: 0.9959441863738738, Validation loss: 2.922204852104187, Validation accuracy: 0.4758234797297297\n",
      "Epoch: 690, Training loss: 0.05141395144164562, Training accuracy: 0.9885099943693694, Validation loss: 3.109421968460083, Validation accuracy: 0.45750633445945943\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001, amsgrad=True)\n",
    "epochs = 1000\n",
    "verbose_step = 10\n",
    "min_validation_loss = np.float32('inf')\n",
    "\n",
    "# Epoch runner\n",
    "for epoch in range(epochs):\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    validation_loss = []\n",
    "    validation_accuracy = []\n",
    "\n",
    "    # Training\n",
    "    for inputs, targets in train_imagedataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(inputs.unsqueeze(axis=1).to(device))\n",
    "        loss = criterion(outputs, targets.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss.append(loss.mean().item())\n",
    "        training_accuracy.append((torch.nn.functional.softmax(outputs, dim=1).cpu().detach().numpy().argmax(axis=1)==targets.cpu().detach().numpy()).sum()/len(targets))\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_imagedataloader:\n",
    "            outputs = cnn_model(inputs.unsqueeze(axis=1).to(device))\n",
    "            loss = criterion(outputs, targets.to(device))\n",
    "            validation_loss.append(loss.mean().item())\n",
    "            validation_accuracy.append((torch.nn.functional.softmax(outputs, dim=1).cpu().detach().numpy().argmax(axis=1)==targets.cpu().detach().numpy()).sum()/len(targets))\n",
    "    \n",
    "    # Verbose metrics\n",
    "    if (epoch+1)%verbose_step==0:\n",
    "        print(f\"Epoch: {epoch+1}\", end=\", \")\n",
    "        print(\"Training loss:\", np.mean(training_loss), end=\", \")\n",
    "        print(\"Training accuracy:\", np.mean(training_accuracy), end=\", \")\n",
    "        print(\"Validation loss:\", np.mean(validation_loss), end=\", \")\n",
    "        print(\"Validation accuracy:\", np.mean(validation_accuracy))\n",
    "    \n",
    "    # Save\n",
    "    if np.mean(validation_loss) < min_validation_loss:\n",
    "        min_validation_loss = np.mean(validation_loss)\n",
    "        torch.save(cnn_model.state_dict(), \"../models/cnn_v1_stdmfcc2D_2.5ms.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9a5fd77c4145bf0d5075e8f6c2878b697c65676cd372abdf0fd157b274620be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('kagglenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
